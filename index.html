<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>GRIG-inpainting</title>
	<meta property="og:image" content="resources/framework.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="GRIG: Few-Shot Generative Residual Image Inpainting" />
	<meta property="og:description" content="Image inpainting is the task of filling in missing or masked region of an image with semantically meaningful contents. Recent methods have shown significant improvement in dealing with large-scale missing regions. However, these methods usually require large training datasets to achieve satisfactory results and there has been limited research into training these models on a small number of samples. To address this, we present a novel few-shot generative residual image inpainting method that produces high-quality inpainting results. The core idea is to propose an iterative residual reasoning method that incorporates Convolutional Neural Networks (CNNs) for feature extraction and Transformers for global reasoning within generative adversarial networks, along with image-level and patch-level discriminators. We also propose a novel forgery-patch adversarial training strategy to create faithful textures and detailed appearances. Extensive evaluations show that our method outperforms previous methods on the few-shot image inpainting task, both quantitatively and qualitatively." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:36px">GRIG: Few-Shot Generative Residual Image Inpainting</span>
		<table align=center width=1200px>
			<table align=center width=1200px>
				<tr>
					<td align=center width=200px>
						<center>
							<span style="font-size:18px"><a href="https://longlongaaago.github.io/">Wanglong Lu</a></span>
						</center>
					</td>
					<td align=center width=200px>
						<center>
							<span style="font-size:18px"><a href="http://www.cs.mun.ca/~xiantaj/">Xianta Jiang</a></span>
						</center>
					</td>
					<td align=center width=200px>
						<center>
							<span style="font-size:18px"><a href="http://www.cad.zju.edu.cn/home/jin/">Xiaogang Jin</a></span>
						</center>
					</td>
					<td align=center width=200px>
						<center>
							<span style="font-size:18px"><a href="https://www.yongliangyang.net/">Yongliang Yang</a></span>
						</center>
					</td>
					<td align=center width=200px>
						<center>
							<span style="font-size:18px"><a href="http://socs.uoguelph.ca/~minglun/">Minglun Gong</a></span>
						</center>
					</td>
					<td align=center width=200px>
						<center>
							<span style="font-size:18px"><a href="https://taowangzj.github.io/">Tao Wang</a></span>
						</center>
					</td>
					<td align=center width=200px>
						<center>
							<span style="font-size:18px"><a href="">Kaijie Shi</a></span>
						</center>
					</td>
					<td align=center width=200px>
						<center>
							<span style="font-size:18px"><a href="http://i3s.wzu.edu.cn/info/1104/1183.htm">Hanli Zhao*</a></span>
						</center>
					</td>
					<td align=center width=200px>
				</tr>
			</table>
			<table align=center width=250px>
				<tr>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://arxiv.org/abs/2304.12035'>[Paper]</a></span>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://github.com/LonglongaaaGo/GRIG_few_shot_inpainting'>[GitHub]</a></span><br>
						</center>
					</td>
				</tr>
			</table>
		</table>
	</center>

	<center>
		<table align=center width=850px>
			<tr>
				<td width=260px>
					<center>
						<img class="round" style="width:1000px" src="./resources/framework.png"/>
					</center>
				</td>
			</tr>
		</table>
		
		<table align=center width=850px>
			<tr>
				<td>
					<span style="font-size:18px">
					<div style="text-align: justify"> 
					Overall pipeline of our few-shot generative residual image inpainting framework (GRIG).
					</div>
					</span>
				</td>
			</tr>
		</table>
	</center>

	<hr>

	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
			<span style="font-size:18px">
				<div style="text-align: justify"> 
Image inpainting is the task of filling in missing or masked region of an image with semantically meaningful contents. Recent methods have shown significant improvement in dealing with large-scale missing regions. However, these methods usually require large training datasets to achieve satisfactory results and there has been limited research into training these models on a small number of samples. To address this, we present a novel few-shot generative residual image inpainting method that produces high-quality inpainting results. The core idea is to propose an iterative residual reasoning method that incorporates Convolutional Neural Networks (CNNs) for feature extraction and Transformers for global reasoning within generative adversarial networks, along with image-level and patch-level discriminators. We also propose a novel forgery-patch adversarial training strategy to create faithful textures and detailed appearances. Extensive evaluations show that our method outperforms previous methods on the few-shot image inpainting task, both quantitatively and qualitatively.				</div>
			</span>
			</td>
		</tr>
	</table>
	<br>

	
	<hr>
	<center><h1>Demo vedio</h1></center>
	<p align="center">
		<iframe width="660" height="395" src="https://www.youtube.com/embed/czB3VAwhB0o?si=mcNZYT_lmBJPR9m5" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe>
		<br>
		<span style="font-size:18px"><a href="//player.bilibili.com/player.html?aid=358757940&bvid=BV13X4y1n7T8&cid=1206882830&p=1">BiliBIli channel</a></span>

	</p>
	<!--
	<table align=center width=800px>
		<br>
		<tr>
			<center>
				<span style="font-size:28px"><a href=''>[Slides]</a>
				</span>
			</center>
		</tr>
	</table>
	<hr>
	-->
	
	
	
	<table align=center width=800px>
		<br>
		<tr><center>
			<span style="font-size:28px">&nbsp;<a href='https://github.com/LonglongaaaGo/GRIG_few_shot_inpainting'>[GitHub]</a>
			</center>
		</tr>
		</span>
	</table>
	<br>
	<hr>
	<table align=center width=600px>
		<center><h1>Paper and Supplementary Material</h1></center>
		<tr>
			<td><a href=""><img class="layered-paper-big" style="height:175px" src="./resources/paper_page.png"/></a></td>
			<td><span style="font-size:14pt">Wanglong Lu and Xianta Jiang and Xiaogang Jin and Yong-Liang Yang and Minglun Gong and Tao Wang and Kaijie Shi and Hanli Zhao.<br>
				<b>GRIG: Few-Shot Generative Residual Image Inpainting </b>
				<!--<br>In Conference, 20XX.<br>-->
				(hosted on <a href="https://arxiv.org/abs/2304.12035">ArXiv</a>)<br>
				<!-- (<a href="./resources/camera-ready.pdf">camera ready</a>)<br> -->
				<span style="font-size:4pt"><a href=""><br></a>
				</span>
			</td>
		</tr>
	</table>
	<br>

	<table align=center width=600px>
		<tr>
			<td><span style="font-size:14pt"><center>
				<a href="./resources/bibtex.txt">[Bibtex]</a>
			</center></td>
		</tr>
	</table>

	<hr>
	<br>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					
					
<!--					We thank Serguei Vassiliev for code debugging, Tao Wang and Jingjing Zheng for helpful discussion, and 63 volunteers for the user survey.<br />-->
					This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; Thanks for their awesome work!</a>
					
					
				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>

